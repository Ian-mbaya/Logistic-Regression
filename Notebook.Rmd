---
title: "Logistic Regression  Project"
author: "Ian Mbaya"
date: "2024-04-25"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load the Neccessary Libraries

```{r Load-libraries}
library('tidyverse')
library('tidymodels')
library('caret')
library('pROC')
library('lubridate')
library('writexl')
library('knitr')
```

# Loading the Data

## I am using data1 because of size constraints. The original file was too big for github

```{r load-data}
#attacks <- read.csv("data/CTU1.csv", sep = "|") Deleted File
attacks <- readxl::read_xlsx("data/data1.xlsx")
```

# Preliminary Data Analysis

## Take a Glimpse of the Data

```{r}
dplyr::glimpse(attacks)
```

## Data Summary

```{r}
summary(attacks)
```

## Checking for Missing Values

```{r}
skimr::skim(attacks)
```

## Create a Data Dictionary

```{r Data-Dictionary}
# Data Dictionary for Network Connection Data
data_dictionary <- tibble::tribble(
  ~Field_Name,     ~Description,                                   ~Type,
  "ts",            "The timestamp of the connection event.",      "time",
  "uid",           "A unique identifier for the connection.",     "string",
  "id.orig_h",     "The source IP address.",                      "addr",
  "id.orig_p",     "The source port.",                            "port",
  "id.resp_h",     "The destination IP address.",                 "addr",
  "id.resp_p",     "The destination port.",                       "port",
  "proto",         "The network protocol used (e.g., 'tcp').",    "enum",
  "service",       "The service associated with the connection.", "string",
  "duration",      "The duration of the connection.",             "interval",
  "orig_bytes",    "The number of bytes sent from the source to the destination.", "count",
  "resp_bytes",    "The number of bytes sent from the destination to the source.", "count",
  "conn_state",    "The state of the connection.",                "string",
  "local_orig",    "Indicates whether the connection is considered local or not.", "bool",
  "local_resp",    "Indicates whether the connection is considered local or not.", "bool",
  "missed_bytes",  "The number of missed bytes in the connection.", "count",
  "history",       "A history of connection states.",             "string",
  "orig_pkts",     "The number of packets sent from the source to the destination.", "count",
  "orig_ip_bytes", "The number of IP bytes sent from the source to the destination.", "count",
  "resp_pkts",     "The number of packets sent from the destination to the source.", "count",
  "resp_ip_bytes", "The number of IP bytes sent from the destination to the source.", "count",
  "tunnel_parents","Indicates if this connection is part of a tunnel.", "set[string]",
  "label",         "A label associated with the connection (e.g., 'Malicious' or 'Benign').", "string",
  "detailed_label","A more detailed description or label for the connection.", "string"
)

```

From the summary and glimpse functions above it seems like we might have too many variables that may not be contributing to the model. While the skim functions shows that there are no missing values some of the variables have a dash has placeholder "-". In the following steps we will be further exploring and visualizing the data to identify trends and patterns in the data that will determine the most important variables for prediction.

# Data Processing, Exploration Feature Engineering.

## Correlation Analysis

Running A Correlation Analysis to Identify the variables that have the highest corellation with network traffic label.

```{r}

# Check the levels of the label variable
levels(attacks$label)

# Convert label to a factor if it's not already
attacks$label <- as.factor(attacks$label)

# Calculate correlation using Cramér's V for categorical variables
cramer_v <- function(x, y) {
  confusion_matrix <- table(x, y)
  n <- sum(confusion_matrix)
  chi_sq <- chisq.test(confusion_matrix)$statistic
  return(sqrt(chi_sq / (n * (min(nrow(confusion_matrix), ncol(confusion_matrix)) - 1))))
}

# Calculate correlation between label and each categorical variable
correlation_results <- lapply(attacks[, -which(names(attacks) == "label")], cramer_v, y = attacks$label)

# Convert the results to a data frame
correlation_df <- data.frame(
  variable = names(correlation_results),
  correlation = unlist(correlation_results)
)

# Visualize correlation
ggplot(correlation_df, aes(x = reorder(variable, correlation), y = correlation)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  coord_flip() +
  labs(x = "Variable", y = "Correlation (Cramér's V)",
       title = "Correlation between Variables and Label") +
  theme_minimal()

```
In the first iteration there were 23 variables, I opted to remove all the variables that had a correlation of less than 0.75 and columns  that  had all values set to "-" the placeholder for missing.
This alllowed me to save on time and space when running the models and also allowed me to upload the Project to GitHub without getting the error file is too large.

## Visualizing Pattern in Network Traffic based on Timestamps

```{r}

# Convert 'ts' to a DateTime object 
attacks$ts <- as.POSIXct(attacks$ts, format = "%Y-%m-%d %H:%M:%S")  

# Create a new dataframe with counts of attacks per time period (e.g., per day)
attacks_per_period <- attacks %>%
  group_by(ts = floor_date(ts, "day"), label) %>%  # group by day and label;  
  summarise(count = n(), .groups = 'drop')  # count the number of rows (attacks) per group

# Create the time series plot
ggplot(attacks_per_period, aes(x = ts, y = count, group = label, color = label)) +
  geom_line() +  
  labs(title = "Time Series of Attacks", x = "Time", y = "Count of Attacks", color = "Label") +
  theme_minimal() +
  scale_x_datetime(date_breaks = "1 day", date_labels = "%b %d")  

```
The line charts shows that both Malicious and Benign attacks  follow the same pattern. Although the data shows that there are more malicious requests in this particular data set.

## Visualizing the Number of Bytes Sent from Origin

```{r}
# Calculate the 99th percentile to identify the 1% threshold
percentile_99 <- quantile(attacks$orig_ip_bytes, probs = 0.99)

# Create a density plot with a more focused x-axis limit
ggplot(attacks, aes(x = orig_ip_bytes, fill = label)) +
  geom_density(alpha = 0.5, trim = TRUE) +  # Trim the density to limit the plot
  labs(x = "Number of Bytes Sent from Origin",
       y = "Density",
       title = "Density Plot of Number of Bytes Sent from Origin by Label") +
  scale_fill_manual(values = c("#1f78b4", "#33a02c")) +  # Custom colors for the fill
  theme_minimal() +
  xlim(c(0, max(180, percentile_99)))  # Set x-axis limits to highlight the 1% tail

```
The density charts shows that request that send over 60 bytes  from the  origin Ip address tend to be mostly malicious. Most benign requests send less than 50  bytesfrom the origin IP.

## Exploring the Categorical Variables History, ID.Resp_p, ID.Resp_p, ID.Resp_h, ID.Resp_p, Proto (All have high correaltions with label)

```{r}
# Determine the number of unique values for each variable
num_unique_history <- attacks %>% select(history) %>% n_distinct()
num_unique_id_resp_p <- attacks %>% select(id.resp_p) %>% n_distinct()
num_unique_id_resp_h <- attacks %>% select(id.resp_h) %>% n_distinct()
num_unique_id_orig_h <- attacks %>% select(id.orig_p) %>% n_distinct()
num_unique_proto <- attacks %>% select(proto) %>% n_distinct()

# Create a data frame to store the results
unique_values_df <- data.frame(
  variable = c("id.resp_p", "id.resp_h", "id.orig_p", "proto", "history"),
  unique_values = c(num_unique_id_resp_p, num_unique_id_resp_h, num_unique_id_orig_h, num_unique_proto, num_unique_history)
)

# Use kable for presentation
kable(unique_values_df, caption = "Number of Unique Values in Each Variable")

```
Of the FIVE  categorical models picked  from the first iteration (cor > 0.75 and non missing) only one (protocol) seem to be appropriate for linear regression model. The destination and  origin (IP addresses and Ports), and network history have very large dimensionality so they  can only be fit into a regression model after  rigorous stemming and lemitization that I did not have the resources to implement.
However I opted to use wordcloud to visualize how the different values of history appear in the dataset.

##Visualizing The Categorical Variables History with a WordCloud

```{r}
# Load necessary libraries
library(wordcloud)

# Filter out "unknown" values
attacks_filtered <- subset(attacks, history != "unknown")

# Create separate datasets for malicious and benign
malicious_data <- subset(attacks_filtered, label == "Malicious")
benign_data <- subset(attacks_filtered, label == "Benign")

# Create word cloud for malicious data
wordcloud(malicious_data$history, scale=c(5,0.5), min.freq = 10, random.order=FALSE, colors=brewer.pal(8, "Dark2"), main="Malicious")

# Create word cloud for benign data
wordcloud(benign_data$history, scale=c(5,0.5), min.freq = 10, random.order=FALSE, colors=brewer.pal(8, "Dark2"), main="Benign")

```
The two  worldclouds confirm my  intial sentiments with the history "haddaaff" dominating benign request and all the other states  in the malicious set. 

##Visualizing The Protocols Values on a Barchart

```{r categorical-viz}
# Ensure all varaibales are factors
attacks$label <- as.factor(attacks$label)
attacks$proto <- as.factor(attacks$proto)

# Plot1 Protocols
ggplot(data = attacks, aes(x = proto, fill = label)) +
  geom_bar(position = "dodge") +
  labs(title = "Distribution of Labels across Protocols",
       x = "Protocols",
       y = "Count") +
  scale_fill_brewer(palette = "Set1")  

```
The Data appaers to be very skewed with  most  of the  malicious attacks  concentrated in the tcp protocol and benign attacks  in the udp protocol.

## Dimensionality Reduction

This was the most challenging part of the project I attempted differerent approaches like using a stepwise linear discrimination, lemitization of IP addresses and ports to reduce dimensionality with limited success. I opted to create a subset of the data since I was also having problems pushing the huge original data file to Github. I  decide to create a subset of the data with only the varaibles that I was using in my project.

```{r}
# Removing some of the less  important variables from the data 
data1 <- select(attacks, 
                        label, ts, 
                        id.resp_h, id.resp_p, id.orig_p,
                        proto, history, orig_ip_bytes)

# View the first few rows of the selected data
summary(data1)

```

### Export the Subset For Use in Second Iteration of the Project
```{r}
#write_xlsx(data1, path = "data/data1.xlsx") 
#Used in the first Iteration to create current Data Set
```




## Separating Data into Train and Test

The train data will be used to calibrate the data and the test will be used to validate model predictions and generate a ROC curve.

```{r train-test}
# Create a data partition
set.seed(5774)  
trainIndex <- createDataPartition(data1$label, p = 0.7, list = FALSE, times = 1)

# Create training and test datasets
train <- data1[trainIndex, ]
test <- data1[-trainIndex, ]

# Viewing the dimensions of the train and test sets
dim(train)
dim(test)

```

```{r}
# Count the number of occurrences for each level of the 'label' variable
label_counts <- table(attacks$label)

# Print the counts
print(label_counts)

```

## Logistic Regression Model

Our Logistic Regression Model will thus use the number of bytes sent from the origin and network protocol to determine if a network request is malicious or benign. The base equation for this model is

$$
\begin{equation*}
\log\left(\frac{p_i}{1-p_i}\right) = \beta_0 + \beta_1 \times orig\_ip\_bytes + \beta_2 \times proto
\end{equation*}
$$ \


```{r logistic-model}

# Running a logistic regression model with received_callback as the response variable
# and years_experience, race, and gender as explanatory variables

mult_log_mod <- glm(label ~ orig_ip_bytes + proto, 
                      data = train, 
                      family = binomial)

# Displaying the summary of the model
tidy(mult_log_mod)

```

## Results

### Equation for icmp

$$
\begin{equation*}
\log\left(\frac{p_i}{1-p_i}\right) = \ -17.66528932 + \ 0.00112571 \times orig\_ip\_bytes 
\end{equation*}
$$ \

>Intercept (β0): −17.66528932 represents the log odds of the outcome when all predictors are at their reference level O bytes sent sent and icmp protocol.
>Coefficient for orig_ip_bytes (β1): The coefficient 0.00112571, indicates the amount of change in the log odds of the outcome for a one-unit increase in 'orig_ip_bytes'.

### Equation for TCP
$$
\begin{equation*}
\log\left(\frac{p_i}{1-p_i}\right) = \ -17.66528932 + \ 0.00112571 \times orig\_ip\_bytes + \ 8.19231031 \times prototcp
\end{equation*}
$$ \

>Coefficient for prototcp is 8.19231031 this tells us that when the protocol is TCP (as opposed to ICMP), the likelihood of a malicious is 8.19231031 units higher than when the protocol is ICMP, while holding bytes sent from origin constant.


### Equation for UDP
$$
\begin{equation*}
\log\left(\frac{p_i}{1-p_i}\right) = \ -17.66528932 + \ 0.00112571 \times orig\_ip\_bytes + \ 20.06098491 \times protoudp
\end{equation*}
$$ \

>Coefficient for prototcp is 20.06098491 this tells us that when the protocol is TCP (as opposed to ICMP), the likelihood of a malicious is 20.06098491 units higher than when the protocol is ICMP, while holding bytes sent from origin constant. 

### Cross Validation

```{r}
# Create 10-fold cross-validation sets
set.seed(123) # for reproducibility
folds <- createFolds(train$label, k = 10)

# Function to perform cross-validation and compute AUC for each fold
cv_roc_auc <- function(train_data, folds) {
  auc_list <- c()
  
  for(i in 1:length(folds)) {
    # Splitting data into training and test sets
    test_indices <- folds[[i]]
    train_indices <- setdiff(seq_len(nrow(train_data)), test_indices)
    
    train_fold <- train_data[train_indices, ]
    test_fold <- train_data[test_indices, ]
    
    # Fit the model on the training set
    glm_model <- glm(label ~ orig_ip_bytes + proto, data = train_fold, family = binomial)
    
    # Predict probabilities on the test set
    prob_predictions <- predict(glm_model, newdata = test_fold, type = "response")
    
    # Compute ROC AUC
    roc_curve <- roc(test_fold$label, prob_predictions)
    auc_value <- auc(roc_curve)
    auc_list <- c(auc_list, auc_value)
  }
  
  return(auc_list)
}

# Perform cross-validation and compute AUC
auc_results <- cv_roc_auc(train, folds)

# Calculate the mean AUC from all folds
mean_auc <- mean(auc_results)

# Output the results
print(paste("Mean AUC from cross-validation:", mean_auc))

```

### ROC Curve
```{r}
# First, predict the probabilities on the validation set (Split Test Data)
prob_predictions <- predict(mult_log_mod, newdata = test, type = "response")

# Generate the ROC object
roc_obj <- roc(test$label, prob_predictions)

# Plot the ROC curve
plot(roc_obj, main = "ROC Curve", col = "#1c61b6", lwd = 2)
# Add AUC to the plot
auc(roc_obj)

```

## Conlusions and Reccommenadtions
AUC is approximately 0.954, which is very close to 1, indicating that the model has excellent discriminative ability to distinguish between the malicious and benign requests.

However this  result should be taken with a grain of salt  since the  data is  higly  skewed  with majority of Malicious attacks concentrated in the TCP protocol  while a majority of  benign attacks in the udp protocol.

A better approach  to determine  the  efficiency of this model would be to use a more balanced dataset that distributes requests across the  protocols. Further effort to lemitize and stem  the IP addresses, Ports, History(Connections) would also help  in providing more insightful patterns on network traffic and improving the models  efficiency.

Also different approaches  to discriminant analysis (instead of the cramer's correlation) and clustering (instead of logistic regression) would have  probably yielded different results.

