---
title: "Logistic Regression  Project"
author: "Ian Mbaya"
date: "2024-04-25"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load the Neccessary Libraries

```{r Load-libraries}
library('tidyverse')
library('tidymodels')
library('caret')
library('pROC')
library('lubridate')
library('writexl')
library('knitr')
```

# Loading the Data

## I am using data1 because of size constraints. The original file was too big for github

```{r load-data}
#attacks <- read.csv("data/CTU1.csv", sep = "|") Deleted File
attacks <- readxl::read_xlsx("data/data1.xlsx")
```

# Preliminary Data Analysis

## Take a Glimpse of the Data

```{r}
dplyr::glimpse(attacks)
```

## Data Summary

```{r}
summary(attacks)
```

## Checking for Missing Values

```{r}
skimr::skim(attacks)
```

## Create a Data Dictionary

```{r Data-Dictionary}
# Data Dictionary for Network Connection Data
data_dictionary <- tibble::tribble(
  ~Field_Name,     ~Description,                                   ~Type,
  "ts",            "The timestamp of the connection event.",      "time",
  "uid",           "A unique identifier for the connection.",     "string",
  "id.orig_h",     "The source IP address.",                      "addr",
  "id.orig_p",     "The source port.",                            "port",
  "id.resp_h",     "The destination IP address.",                 "addr",
  "id.resp_p",     "The destination port.",                       "port",
  "proto",         "The network protocol used (e.g., 'tcp').",    "enum",
  "service",       "The service associated with the connection.", "string",
  "duration",      "The duration of the connection.",             "interval",
  "orig_bytes",    "The number of bytes sent from the source to the destination.", "count",
  "resp_bytes",    "The number of bytes sent from the destination to the source.", "count",
  "conn_state",    "The state of the connection.",                "string",
  "local_orig",    "Indicates whether the connection is considered local or not.", "bool",
  "local_resp",    "Indicates whether the connection is considered local or not.", "bool",
  "missed_bytes",  "The number of missed bytes in the connection.", "count",
  "history",       "A history of connection states.",             "string",
  "orig_pkts",     "The number of packets sent from the source to the destination.", "count",
  "orig_ip_bytes", "The number of IP bytes sent from the source to the destination.", "count",
  "resp_pkts",     "The number of packets sent from the destination to the source.", "count",
  "resp_ip_bytes", "The number of IP bytes sent from the destination to the source.", "count",
  "tunnel_parents","Indicates if this connection is part of a tunnel.", "set[string]",
  "label",         "A label associated with the connection (e.g., 'Malicious' or 'Benign').", "string",
  "detailed_label","A more detailed description or label for the connection.", "string"
)

```

From the summary and glimpse functions above it seems like we might have too many variables that may not be contributing to the model. While the skim functions shows that there are no missing values some of the variables have a dash has placeholder "-". In the following steps we will be further exploring and visualizing the data to identify trends and patterns in the data that will determine the most important variables for prediction.

# Data Processing, Exploration Feature Engineering.

## Correlation Analysis

Running A Correlation Analysis to Identify the variables that have the highest corellation with network traffic label.

```{r}

# Check the levels of the label variable
levels(attacks$label)

# Convert label to a factor if it's not already
attacks$label <- as.factor(attacks$label)

# Calculate correlation using Cramér's V for categorical variables
cramer_v <- function(x, y) {
  confusion_matrix <- table(x, y)
  n <- sum(confusion_matrix)
  chi_sq <- chisq.test(confusion_matrix)$statistic
  return(sqrt(chi_sq / (n * (min(nrow(confusion_matrix), ncol(confusion_matrix)) - 1))))
}

# Calculate correlation between label and each categorical variable
correlation_results <- lapply(attacks[, -which(names(attacks) == "label")], cramer_v, y = attacks$label)

# Convert the results to a data frame
correlation_df <- data.frame(
  variable = names(correlation_results),
  correlation = unlist(correlation_results)
)

# Visualize correlation
ggplot(correlation_df, aes(x = reorder(variable, correlation), y = correlation)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  coord_flip() +
  labs(x = "Variable", y = "Correlation (Cramér's V)",
       title = "Correlation between Variables and Label") +
  theme_minimal()

```

## Visualizing Pattern in Network Traffic based on Timestamps

```{r}

# Convert 'ts' to a DateTime object 
attacks$ts <- as.POSIXct(attacks$ts, format = "%Y-%m-%d %H:%M:%S")  

# Create a new dataframe with counts of attacks per time period (e.g., per day)
attacks_per_period <- attacks %>%
  group_by(ts = floor_date(ts, "day"), label) %>%  # group by day and label;  
  summarise(count = n(), .groups = 'drop')  # count the number of rows (attacks) per group

# Create the time series plot
ggplot(attacks_per_period, aes(x = ts, y = count, group = label, color = label)) +
  geom_line() +  
  labs(title = "Time Series of Attacks", x = "Time", y = "Count of Attacks", color = "Label") +
  theme_minimal() +
  scale_x_datetime(date_breaks = "1 day", date_labels = "%b %d")  

```

## Visualizing the Number of Bytes Sent from Origin

```{r}
# Calculate the 99th percentile to identify the 1% threshold
percentile_99 <- quantile(attacks$orig_ip_bytes, probs = 0.99)

# Create a density plot with a more focused x-axis limit
ggplot(attacks, aes(x = orig_ip_bytes, fill = label)) +
  geom_density(alpha = 0.5, trim = TRUE) +  # Trim the density to limit the plot
  labs(x = "Number of Bytes Sent from Origin",
       y = "Density",
       title = "Density Plot of Number of Bytes Sent from Origin by Label") +
  scale_fill_manual(values = c("#1f78b4", "#33a02c")) +  # Custom colors for the fill
  theme_minimal() +
  xlim(c(0, max(180, percentile_99)))  # Set x-axis limits to highlight the 1% tail

```

## Exploring the Categorical Variables History, ID.Resp_p, ID.Resp_p, ID.Resp_h, ID.Resp_p, Proto (All have high correaltions with label)

```{r}
# Determine the number of unique values for each variable
num_unique_history <- attacks %>% select(history) %>% n_distinct()
num_unique_id_resp_p <- attacks %>% select(id.resp_p) %>% n_distinct()
num_unique_id_resp_h <- attacks %>% select(id.resp_h) %>% n_distinct()
num_unique_id_orig_h <- attacks %>% select(id.orig_p) %>% n_distinct()
num_unique_proto <- attacks %>% select(proto) %>% n_distinct()

# Create a data frame to store the results
unique_values_df <- data.frame(
  variable = c("id.resp_p", "id.resp_h", "id.orig_p", "proto", "history"),
  unique_values = c(num_unique_id_resp_p, num_unique_id_resp_h, num_unique_id_orig_h, num_unique_proto, num_unique_history)
)

# Use kable for presentation
kable(unique_values_df, caption = "Number of Unique Values in Each Variable")

```

##Visualizing The Categorical Variables History with a WordCloud

```{r}
# Load necessary libraries
library(wordcloud)

# Filter out "unknown" values
attacks_filtered <- subset(attacks, history != "unknown")

# Create separate datasets for malicious and benign
malicious_data <- subset(attacks_filtered, label == "Malicious")
benign_data <- subset(attacks_filtered, label == "Benign")

# Create word cloud for malicious data
wordcloud(malicious_data$history, scale=c(5,0.5), min.freq = 10, random.order=FALSE, colors=brewer.pal(8, "Dark2"), main="Malicious")

# Create word cloud for benign data
wordcloud(benign_data$history, scale=c(5,0.5), min.freq = 10, random.order=FALSE, colors=brewer.pal(8, "Dark2"), main="Benign")

```

##Visualizing The Protocols Values on a Barchart

```{r categorical-viz}
# Ensure all varaibales are factors
attacks$label <- as.factor(attacks$label)
attacks$proto <- as.factor(attacks$proto)

# Plot1 Protocols
ggplot(data = attacks, aes(x = proto, fill = label)) +
  geom_bar(position = "dodge") +
  labs(title = "Distribution of Labels across Protocols",
       x = "Protocols",
       y = "Count") +
  scale_fill_brewer(palette = "Set1")  

```

## Dimensionality Reduction

This was the most challenging part of the project I attempted differerent approaches like using a stepwise linear discrimination, lemitization of IP addresses and ports to reduce dimensionality with limited success. I opted to create a subset of the data since I was also having problems pushing the huge original data file to Github. I  decide to create a subset of the data with only the varaibles that I was using in my project.

```{r}
# Removing some of the less  important variables from the data 
data1 <- select(attacks, 
                        label, ts, 
                        id.resp_h, id.resp_p, id.orig_p,
                        proto, history, orig_ip_bytes)

# View the first few rows of the selected data
summary(data1)

```

### Export the Subset For Use in Second Iteration of the Project
```{r}
#write_xlsx(data1, path = "data/data1.xlsx") 
#Used in the first Iteration to create current Data Set
```




## Separating Data into Train and Test

The train data will be used to calibrate the data and the test will be used to validate model predictions and generate a ROC curve.

```{r train-test}
# Create a data partition
set.seed(5774)  
trainIndex <- createDataPartition(data1$label, p = 0.7, list = FALSE, times = 1)

# Create training and test datasets
train <- data1[trainIndex, ]
test <- data1[-trainIndex, ]

# Viewing the dimensions of the train and test sets
dim(train)
dim(test)

```

```{r}
# Count the number of occurrences for each level of the 'label' variable
label_counts <- table(attacks$label)

# Print the counts
print(label_counts)

```

## Logistic Regression Model

Our Logistic Regression Model will thus use the number of bytes sent from the origin and network protocol to determine if a network request is malicious or benign. The base equation for this model is

$$
\begin{equation*}
\log\left(\frac{p_i}{1-p_i}\right) = \beta_0 + \beta_1 \times orig\_ip\_bytes + \beta_3 \times proto
\end{equation*}
$$ \


```{r logistic-model}

# Running a logistic regression model with received_callback as the response variable
# and years_experience, race, and gender as explanatory variables

mult_log_mod <- glm(label ~ orig_ip_bytes + proto, 
                      data = train, 
                      family = binomial)

# Displaying the summary of the model
tidy(mult_log_mod)

```

## Results

### Equation for icmp

$$
\begin{equation*}
\log\left(\frac{p_i}{1-p_i}\right) = \beta_0 + \beta_1 \times orig\_ip\_bytes + \beta_3 \times proto
\end{equation*}
$$ \

### Equation for TCP

$$
\begin{equation*}
\log\left(\frac{p_i}{1-p_i}\right) = \beta_0 + \beta_1 \times orig\_ip\_bytes + \beta_3 \times proto
\end{equation*}
$$ 


### Equation for UDP

$$
\begin{equation*}
\log\left(\frac{p_i}{1-p_i}\right) = \beta_0 + \beta_1 \times orig\_ip\_bytes + \beta_3 \times proto
\end{equation*}
$$ 

### Cross Validation

```{r}
# Create 10-fold cross-validation sets
set.seed(123) # for reproducibility
folds <- createFolds(train$label, k = 10)

# Function to perform cross-validation and compute AUC for each fold
cv_roc_auc <- function(train_data, folds) {
  auc_list <- c()
  
  for(i in 1:length(folds)) {
    # Splitting data into training and test sets
    test_indices <- folds[[i]]
    train_indices <- setdiff(seq_len(nrow(train_data)), test_indices)
    
    train_fold <- train_data[train_indices, ]
    test_fold <- train_data[test_indices, ]
    
    # Fit the model on the training set
    glm_model <- glm(label ~ orig_ip_bytes + proto, data = train_fold, family = binomial)
    
    # Predict probabilities on the test set
    prob_predictions <- predict(glm_model, newdata = test_fold, type = "response")
    
    # Compute ROC AUC
    roc_curve <- roc(test_fold$label, prob_predictions)
    auc_value <- auc(roc_curve)
    auc_list <- c(auc_list, auc_value)
  }
  
  return(auc_list)
}

# Perform cross-validation and compute AUC
auc_results <- cv_roc_auc(train, folds)

# Calculate the mean AUC from all folds
mean_auc <- mean(auc_results)

# Output the results
print(paste("Mean AUC from cross-validation:", mean_auc))

```

### ROC Curve
```{r}
# First, predict the probabilities on the validation set (Split Test Data)
prob_predictions <- predict(mult_log_mod, newdata = test, type = "response")

# Generate the ROC object
roc_obj <- roc(test$label, prob_predictions)

# Plot the ROC curve
plot(roc_obj, main = "ROC Curve", col = "#1c61b6", lwd = 2)
# Add AUC to the plot
auc(roc_obj)

```

## Conlusions and Reccommenadtions
